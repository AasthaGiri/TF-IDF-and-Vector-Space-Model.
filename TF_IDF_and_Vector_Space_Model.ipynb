{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import re  # Import regular expressions library\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkKG1FmiN1u1",
        "outputId": "99803d76-83ee-4c66-98de-7a1ff9a7e443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOPWORDS = set(stopwords.words('english'))\n",
        "LEMMATIZER = WordNetLemmatizer ()"
      ],
      "metadata": {
        "id": "E0JoYeordrgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_text_files(folder_path):\n",
        "    \"\"\"The program reads every file in a folder and outputs a list of tuples, each of which has the filename and the entire document's text as a string.\"\"\"\n",
        "    data = []\n",
        "    filenames = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            filenames.append(filename)\n",
        "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
        "                single_file = file.read()\n",
        "                data.append(single_file)\n",
        "\n",
        "    return filenames, data"
      ],
      "metadata": {
        "id": "JjZUr_X5dy7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Performs text cleaning: removing special characters, digits, tokenization, stopword removal, and lemmatization.\"\"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and punctuation using regular expressions (keeps only alphanumeric and spaces)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "\n",
        "    # Remove all digits\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # Removes digits globally\n",
        "\n",
        "    # Tokenize the cleaned text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords and lemmatize\n",
        "    cleaned_tokens = [LEMMATIZER.lemmatize(word) for word in tokens if word not in STOPWORDS]\n",
        "\n",
        "    return cleaned_tokens\n"
      ],
      "metadata": {
        "id": "2DfPVV4kd4wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text_queries(text):\n",
        "    \"\"\"Doesn't remove the stopword.\"\"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove special characters and punctuation using regular expressions (keeps only alphanumeric and spaces)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "\n",
        "    # Remove all digits\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # Removes digits globally\n",
        "\n",
        "    # Tokenize the cleaned text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lemmatize only (no stopword removal)\n",
        "    cleaned_tokens = [LEMMATIZER.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return cleaned_tokens\n"
      ],
      "metadata": {
        "id": "GmZ4I43id9uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/dataste'\n",
        "\n",
        "filenames, documents = load_text_files(folder_path)\n",
        "tokenized_docs = [clean_text(doc) for doc in documents]\n",
        "print('tokenized_docs',tokenized_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LOJpf8beBDK",
        "outputId": "cc8b67ad-ba45-43a3-e049-3342f651df6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenized_docs [['sonysupport', 'sony', 'bravia', 'tv', 'keep', 'shutting', 'minute', 'use', 'power', 'indicator', 'flash', 'red', 'ive', 'tried', 'resetting', 'still', 'doesnt', 'work', 'doesnt', 'sound', 'right', 'please', 'dm', 'u', 'tv', 'model', 'number', 'well', 'help', 'troubleshoot', 'issue', 'see', 'repair', 'needed', 'np', 'httpstcotvsupport'], ['samsungsupport', 'galaxy', 'keep', 'restarting', 'randomly', 'throughout', 'day', 'even', 'im', 'anything', 'intensive', 'already', 'tried', 'factory', 'reset', 'didnt', 'help', 'definitely', 'doesnt', 'sound', 'normal', 'please', 'dm', 'u', 'phone', 'model', 'number', 'software', 'version', 'recent', 'change', 'made', 'device', 'well', 'assist', 'troubleshooting', 'ck', 'httpstcodevicehelp'], ['deltahelp', 'arrived', 'destination', 'checked', 'luggage', 'didnt', 'make', 'airline', 'tracker', 'say', 'still', 'departure', 'airport', 'need', 'whats', 'next', 'step', 'really', 'sorry', 'hear', 'luggage', 'issue', 'please', 'dm', 'u', 'booking', 'reference', 'flight', 'detail', 'description', 'bag', 'well', 'help', 'file', 'claim', 'track', 'fg', 'httpstcoluggageclaim'], ['xboxsupport', 'wireless', 'controller', 'disconnect', 'middle', 'game', 'take', 'reconnect', 'happens', 'every', 'minute', 'someone', 'help', 'figure', 'whats', 'going', 'sound', 'frustrating', 'please', 'dm', 'u', 'type', 'console', 'youre', 'using', 'model', 'controller', 'well', 'walk', 'step', 'resolve', 'issue', 'rp', 'httpstcocontrollerhelp'], ['googlehelp', 'gmail', 'app', 'keep', 'getting', 'stuck', 'sending', 'mode', 'whenever', 'try', 'send', 'email', 'even', 'though', 'stable', 'internet', 'connection', 'fix', 'sorry', 'hear', 'please', 'dm', 'u', 'email', 'address', 'youre', 'experiencing', 'issue', 'well', 'app', 'version', 'device', 'youre', 'using', 'well', 'guide', 'troubleshooting', 'step', 'get', 'resolved', 'nl', 'httpstcogmailsupport'], ['verizonsupport', 'internet', 'speed', 'incredibly', 'slow', 'last', 'day', 'even', 'though', 'im', 'supposed', 'unlimited', 'plan', 'someone', 'please', 'look', 'sorry', 'trouble', 'please', 'dm', 'u', 'zip', 'code', 'account', 'information', 'device', 'youre', 'using', 'well', 'check', 'connection', 'right', 'away', 'st', 'httpstcointernetsupport'], ['ubersupport', 'charged', 'cleaning', 'fee', 'trip', 'nothing', 'spilled', 'there', 'way', 'dispute', 'app', 'help', 'get', 'sorted', 'apologize', 'inconvenience', 'please', 'dm', 'u', 'trip', 'detail', 'relevant', 'photo', 'possible', 'well', 'review', 'case', 'provide', 'assistance', 'l', 'httpstcodisputefee'], ['applesupport', 'iphone', 'battery', 'barely', 'last', 'hour', 'recent', 'io', 'update', 'tried', 'usual', 'fix', 'nothing', 'seems', 'work', 'anything', 'else', 'sound', 'frustrating', 'please', 'dm', 'u', 'model', 'number', 'iphone', 'io', 'version', 'youre', 'currently', 'well', 'assist', 'additional', 'troubleshooting', 'step', 'improve', 'battery', 'performance', 'mm', 'httpstcobatteryissues'], ['amazonhelp', 'ordered', 'laptop', 'received', 'toaster', 'instead', 'return', 'option', 'available', 'cant', 'seem', 'get', 'touch', 'customer', 'service', 'help', 'really', 'sorry', 'mixup', 'please', 'dm', 'u', 'order', 'number', 'detail', 'incorrect', 'item', 'received', 'well', 'make', 'sure', 'resolve', 'issue', 'quickly', 'possible', 'jk', 'httpstcohelpcenter'], ['spotifycares', 'every', 'time', 'try', 'play', 'song', 'playlist', 'app', 'crash', 'within', 'second', 'started', 'happening', 'today', 'cant', 'play', 'anything', 'advice', 'sorry', 'inconvenience', 'dm', 'u', 'version', 'app', 'youre', 'using', 'device', 'type', 'possible', 'let', 'u', 'know', 'issue', 'started', 'well', 'work', 'getting', 'fixed', 'lt', 'httpstcosupportspotify']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary (unique words across all documents and queries)\n",
        "vocab = set([word for doc in tokenized_docs for word in doc])\n",
        "vocab = sorted(vocab) # Optional sorting for consistency\n",
        "print(\"Vocabulary:\", vocab)\n"
      ],
      "metadata": {
        "id": "VJ0TQU2jgEXB",
        "outputId": "88ad0504-9c36-4204-c85c-ad7470debf5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['account', 'additional', 'address', 'advice', 'airline', 'airport', 'already', 'amazonhelp', 'anything', 'apologize', 'app', 'applesupport', 'arrived', 'assist', 'assistance', 'available', 'away', 'bag', 'barely', 'battery', 'booking', 'bravia', 'cant', 'case', 'change', 'charged', 'check', 'checked', 'ck', 'claim', 'cleaning', 'code', 'connection', 'console', 'controller', 'crash', 'currently', 'customer', 'day', 'definitely', 'deltahelp', 'departure', 'description', 'destination', 'detail', 'device', 'didnt', 'disconnect', 'dispute', 'dm', 'doesnt', 'else', 'email', 'even', 'every', 'experiencing', 'factory', 'fee', 'fg', 'figure', 'file', 'fix', 'fixed', 'flash', 'flight', 'frustrating', 'galaxy', 'game', 'get', 'getting', 'gmail', 'going', 'googlehelp', 'guide', 'happening', 'happens', 'hear', 'help', 'hour', 'httpstcobatteryissues', 'httpstcocontrollerhelp', 'httpstcodevicehelp', 'httpstcodisputefee', 'httpstcogmailsupport', 'httpstcohelpcenter', 'httpstcointernetsupport', 'httpstcoluggageclaim', 'httpstcosupportspotify', 'httpstcotvsupport', 'im', 'improve', 'inconvenience', 'incorrect', 'incredibly', 'indicator', 'information', 'instead', 'intensive', 'internet', 'io', 'iphone', 'issue', 'item', 'ive', 'jk', 'keep', 'know', 'l', 'laptop', 'last', 'let', 'look', 'lt', 'luggage', 'made', 'make', 'middle', 'minute', 'mixup', 'mm', 'mode', 'model', 'need', 'needed', 'next', 'nl', 'normal', 'nothing', 'np', 'number', 'option', 'order', 'ordered', 'performance', 'phone', 'photo', 'plan', 'play', 'playlist', 'please', 'possible', 'power', 'provide', 'quickly', 'randomly', 'really', 'received', 'recent', 'reconnect', 'red', 'reference', 'relevant', 'repair', 'reset', 'resetting', 'resolve', 'resolved', 'restarting', 'return', 'review', 'right', 'rp', 'samsungsupport', 'say', 'second', 'see', 'seem', 'seems', 'send', 'sending', 'service', 'shutting', 'slow', 'software', 'someone', 'song', 'sony', 'sonysupport', 'sorry', 'sorted', 'sound', 'speed', 'spilled', 'spotifycares', 'st', 'stable', 'started', 'step', 'still', 'stuck', 'supposed', 'sure', 'take', 'there', 'though', 'throughout', 'time', 'toaster', 'today', 'touch', 'track', 'tracker', 'tried', 'trip', 'trouble', 'troubleshoot', 'troubleshooting', 'try', 'tv', 'type', 'u', 'ubersupport', 'unlimited', 'update', 'use', 'using', 'usual', 'verizonsupport', 'version', 'walk', 'way', 'well', 'whats', 'whenever', 'wireless', 'within', 'work', 'xboxsupport', 'youre', 'zip']\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Tokenization\n",
        "# Preprocess documents and queries: lowercase and tokenize\n",
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "tokenized_docs = [tokenize(doc) for doc in documents] # Changed doc to documents\n",
        "tokenized_queries = [tokenize(query) for query in queries]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pnLRzm3Lksne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate term frequency (TF)\n",
        "def term_frequency(term, document):\n",
        "  return document.count(term) / len(document)"
      ],
      "metadata": {
        "id": "LBHfMVPNeOu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate inverse document frequency (IDF)\n",
        "def inverse_document_frequency(term, all_documents):\n",
        "  num_docs_containing_term = sum(1 for doc in all_documents if term in doc)\n",
        "  return math.log(len(all_documents) / (1 + num_docs_containing_term))"
      ],
      "metadata": {
        "id": "NpV8oPATeRaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute TF-IDF for a document\n",
        "def compute_tfidf(document, all_documents, vocab):\n",
        "  tfidf_vector = []\n",
        "  for term in vocab:\n",
        "    tf = term_frequency(term, document)\n",
        "    idf = inverse_document_frequency(term, all_documents)\n",
        "    tfidf_vector.append(tf * idf)\n",
        "  return np.array(tfidf_vector)"
      ],
      "metadata": {
        "id": "Bs_frbd2eTuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity between two vectors\n",
        "def cosine_similarity(vec1, vec2):\n",
        "  dot_product = np.dot(vec1, vec2)\n",
        "  norm_vec1 = np.linalg.norm(vec1)\n",
        "  norm_vec2 = np.linalg.norm(vec2)\n",
        "  return dot_product / (norm_vec1 * norm_vec2)"
      ],
      "metadata": {
        "id": "RZgsG1ExeWJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Queries with logical operators\n",
        "queries = [\n",
        "    \"Why is my internet speed slow despite having an unlimited plan on Verizon?\",\n",
        "    \"What should I do if I receive the wrong item in my Amazon order, and the return option isn’t available?\",\n",
        "    \"How do I fix my iPhone 12 battery draining quickly after the iOS update?\",\n",
        "    \"Why does the Spotify app crash when playing songs on my playlist?\",\n",
        "]"
      ],
      "metadata": {
        "id": "9KzhZZN1ejju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF-IDF vectors for documents and queries\n",
        "doc_tfidf_vectors = [compute_tfidf(doc, tokenized_docs, vocab) for doc in\n",
        "tokenized_docs]\n",
        "query_tfidf_vectors = [compute_tfidf(query, tokenized_docs, vocab) for query in\n",
        "tokenized_queries]"
      ],
      "metadata": {
        "id": "YIMz70Z5eYgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Calculate cosine similarities\n",
        "cosine_similarities = []\n",
        "for query_vector in query_tfidf_vectors:\n",
        "  similarities = [cosine_similarity(query_vector, doc_vector) for doc_vector in doc_tfidf_vectors]\n",
        "  cosine_similarities.append(similarities)\n",
        "\n",
        "# Display the results in order of highest to lowest cosine similarity\n",
        "for i, query in enumerate(queries):\n",
        "    print(f\"\\nCosine similarities for query '{query}':\")\n",
        "\n",
        "    # Zip document indices and their corresponding similarities\n",
        "    doc_sim_pairs = list(enumerate(cosine_similarities[i]))\n",
        "\n",
        "    # Sort the pairs based on similarity in descending order\n",
        "    doc_sim_pairs_sorted = sorted(doc_sim_pairs, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Print the sorted document similarities\n",
        "    for doc_idx, similarity in doc_sim_pairs_sorted:\n",
        "        print(f\"Document {doc_idx + 1}: {similarity:.4f}\")\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89PWf3pPR7Db",
        "outputId": "16e7ec67-37ab-4d18-c305-71409d1ce3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine similarities for query 'Why is my internet speed slow despite having an unlimited plan on Verizon?':\n",
            "Document 6: 0.3957\n",
            "Document 5: 0.0540\n",
            "Document 1: 0.0000\n",
            "Document 2: 0.0000\n",
            "Document 3: 0.0000\n",
            "Document 4: 0.0000\n",
            "Document 7: 0.0000\n",
            "Document 8: 0.0000\n",
            "Document 9: 0.0000\n",
            "Document 10: 0.0000\n",
            "\n",
            "Cosine similarities for query 'What should I do if I receive the wrong item in my Amazon order, and the return option isn’t available?':\n",
            "Document 9: 0.4219\n",
            "Document 1: 0.0000\n",
            "Document 2: 0.0000\n",
            "Document 3: 0.0000\n",
            "Document 4: 0.0000\n",
            "Document 5: 0.0000\n",
            "Document 6: 0.0000\n",
            "Document 7: 0.0000\n",
            "Document 8: 0.0000\n",
            "Document 10: 0.0000\n",
            "\n",
            "Cosine similarities for query 'How do I fix my iPhone 12 battery draining quickly after the iOS update?':\n",
            "Document 8: 0.3617\n",
            "Document 9: 0.1218\n",
            "Document 5: 0.1142\n",
            "Document 1: 0.0000\n",
            "Document 2: 0.0000\n",
            "Document 3: 0.0000\n",
            "Document 4: 0.0000\n",
            "Document 6: 0.0000\n",
            "Document 7: 0.0000\n",
            "Document 10: 0.0000\n",
            "\n",
            "Cosine similarities for query 'Why does the Spotify app crash when playing songs on my playlist?':\n",
            "Document 10: 0.1641\n",
            "Document 5: 0.1583\n",
            "Document 1: 0.0000\n",
            "Document 2: 0.0000\n",
            "Document 3: 0.0000\n",
            "Document 4: 0.0000\n",
            "Document 6: 0.0000\n",
            "Document 7: 0.0000\n",
            "Document 8: 0.0000\n",
            "Document 9: 0.0000\n"
          ]
        }
      ]
    }
  ]
}